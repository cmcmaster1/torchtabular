---
title: "Using Tidymodels and Luz"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Using Tidymodels and Luz}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Load Packages

```{r setup, results='hide', message=FALSE, warning=FALSE}
library(torchtabular)
library(tidymodels)
library(tidyverse)
library(torch)
library(luz)
library(madgrad)
```

# Check for GPU and assign device

```{r}
device <- ifelse(cuda_is_available(), 'cuda', 'cpu')
```


# Load data
The income dataset is included with the {torchtabular} package.

```{r}
data('income')
glimpse(income)
```

## Prepare data
First we will convert the target variable into an integer (0 and 1), and convert
characters to factors so that our tabular dataset will identify them correctly.

```{r}
income <- income %>%
  mutate(across(where(is.character), as_factor),
         income = as.numeric(income) - 1)

glimpse(income)
```

We can now split the data into train and test sets.

```{r}
split <- initial_split(income)
train <- training(split)
valid <- testing(split)
```

By creating a recipe, we the `tabular_dataset` function will automatically
recognise categorical vs. continuous predictors.

```{r}
recipe <- recipe(income, income ~ .) %>%
  step_scale(all_numeric_predictors()) %>%
  step_integer(all_nominal_predictors())
```

We can then pass this recipe to `tabular_dataset` with the relevant split.

```{r}
train_dset <- tabular_dataset(recipe, train)
valid_dset <- tabular_dataset(recipe, valid)
```

Finally, we make a dataloader.

```{r}
train_dl <- dataloader(train_dset,
                       batch_size = 256,
                       shuffle = TRUE)

valid_dl <- dataloader(valid_dset,
                       batch_size = 256,
                       shuffle = TRUE)
```

# Training
We can now train our model using {luz}

```{r}
model_setup <- tabtransformer %>%
  setup(
    loss = nn_bce_with_logits_loss(),
    optimizer = optim_madgrad,
    metrics = list(
      luz_metric_binary_auroc(from_logits = TRUE)
    )
  ) %>%
  set_hparams(categories = train_dset$categories,
              num_continuous = train_dset$num_continuous,
              dim_out = 1,
              intersample = TRUE,
              dim = 32,
              depth = 2,
              heads_selfattn = 4,
              heads_intersample = 4,
              dim_heads_selfattn = 16,
              dim_heads_intersample = 64,
              attn_dropout = 0.1,
              ff_dropout = 0.8,
              mlp_hidden_mult = c(4, 2),
              softmax_mod = 2.5,
              device = device) %>%
  set_opt_hparams(lr = 1e-4)
```

```{r}
fitted <- model_setup %>% 
  fit(train_dl,
      epochs = 10,
      valid_data = valid_dl,
      verbose = TRUE)
```
```{r}
attn_dl <- dataloader(valid_dset,
                       batch_size = 1500,
                       shuffle = FALSE)
```

```{r}
fitted$model <- fitted$model$to(device = 'cpu')
heads <- attention_heads(fitted, valid_dset, 2000)
```

```{r}
heatmap(heads)
```

```{r}
is_heads <- intersample_attention_heads(fitted, valid_dset, 2000)
```

```{r}
library(umap)
mapped <- umap(is_heads)
```

```{r}
y <- as.array(valid_dset$.getitem(1:2000)$y)

cbind(mapped$layout, y) %>% 
  as_tibble() %>% 
  mutate(y = as_factor(y)) %>% 
  ggplot(aes(x = V1, y = V2, col = y)) + 
  geom_point(alpha = 0.5)
```




```{r}
attention_heads <- function(model, dataloader){
  device <- model$model$device
  iter <- dataloader$.iter()
  batch <- iter$.next()
  batch$x$x_cat <- batch$x$x_cat$to(device = device)
  batch$x$x_cont <- batch$x$x_cont$to(device = device)
  full_output <- model$model$predict_attn(batch$x)
  
  attention_matrix <- full_output[[2]][[1]]$mean(c(1,2))$cpu() %>% 
    as.matrix()
  
  names <- colnames(valid_dl$dataset$predictors)
  
  rownames(attention_matrix) <- names
  colnames(attention_matrix) <- names
  
  attention_matrix
}
```


```{r}
valid_dl <- dataloader(valid_dset,
                       batch_size = 1500,
                       shuffle = TRUE)

iter <- valid_dl$.iter()
batch <- iter$.next()
batch$x$x_cat <- batch$x$x_cat$to(device = 'cuda')
batch$x$x_cont <- batch$x$x_cont$to(device = 'cuda')
full_output <- model$model$predict_attn(batch$x)

```


```{r}
vars <- full_output[[2]][[1]]$mean(c(1,2))$cpu() %>% as.matrix()
rownames(vars) <- names(income)[-15]
colnames(vars) <- names(income)[-15]


```














